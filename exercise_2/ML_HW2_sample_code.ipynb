{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KSCsJ0y2XTY"
      },
      "source": [
        "# ML Assignment 2 - Sample Code\n",
        "* 雲端硬碟: https://drive.google.com/drive/folders/1Qhr6vo5zB3hdzpEZ8oG243FlVhLYfn4X?usp=sharing\n",
        "* 蘭花競賽網站: https://tbrain.trendmicro.com.tw/Competitions/Details/20\n",
        "\n",
        "## 執行方式\n",
        "依作業要求，在圖像轉換或修改模型架構區塊更改程式碼，更改完成後，可以直接全部執行。\n",
        "訓練過程及輸出位於最後面。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 初始設定"
      ],
      "metadata": {
        "id": "BOJJwMUtveYP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFMiIumfJBeA"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut6ZO3ltIB9N"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "記得修改cd路徑 這邊ai cup是我自訂的資料夾名稱，副檔會直接產生在colab notebooks下，所以將ai cup這個路徑去掉在執行"
      ],
      "metadata": {
        "id": "VMZdfef0rZw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ai cup"
      ],
      "metadata": {
        "id": "KFmIGG36rZOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.hub import load_state_dict_from_url\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\""
      ],
      "metadata": {
        "id": "uncYZYULmuqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 圖像轉換\n",
        "### 題目\n",
        "torchvision.transforms 提供了許多可靠的 API來讓使用者對圖像進行操作，請試著在 data_transforms 當中對訓練集進行轉換(圖像前處理)，當模型訓練到一定程度時，驗證看看使用該方法是否確實對模型準確率造成影響，然後試著解釋使用該轉換方法會對模型訓練產生什麼影響。\n",
        "\n",
        "* 至少嘗試使用 **五種** 不同的圖像轉換方法，並且找出最佳的方法組合。(使用方法數量為加分bonus的依據)\n",
        "* 須在報告中註明每一個方法 **在未使用時的準確率**、**使用後的準確率**，並 **說明該方法的目的** 及 **最終最佳組合的準確率**。\n",
        "\n",
        "### 說明\n",
        "請在註解區塊中寫入圖像轉換的方法。\n"
      ],
      "metadata": {
        "id": "LsUYQ1BPvH7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((224,224) ),\n",
        "            ########在此區塊填入圖像轉換方法########\n",
        "            \n",
        "\n",
        "            ########################################\n",
        "            transforms.ToTensor(),\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize((224,224) ),\n",
        "            transforms.ToTensor(),\n",
        "        ]),\n",
        "    }"
      ],
      "metadata": {
        "id": "LGtGuG6rni4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 修改模型架構\n",
        "### 第一題 題目\n",
        "在本次作業範例中我們使用了CNN來做為整個分類模型的架構。請以第一題中最佳的圖像轉換方法組合，並基於CNN架構增加或減少模型的隱藏層，並觀察修改模型後對原先準確率的影響(即修改模型的意思)\n",
        "\n",
        "* 至少使用 **三種** 不同隱藏層或不同的修改模型方法(增加或減少模型的隱藏層，並且找出最佳的模型架構。(修改方法多寡為加分bonus的依據)\n",
        "* 須在報告中註明每一個方法 **在更改前的準確率**、 **更改後的準確率** 及 **最終最佳模型架構的準確率**。\n",
        "\n",
        "### 說明\n",
        "* 因為模型有套用預訓練的參數，所以更改模型的方式比較複雜，\n",
        "\n",
        "* 請勿直接更改現有隱藏層的參數(輸入、輸出大小等等)，請用增加或減少的方式來修改模型架構。\n",
        "\n",
        "* 請注意並計算各隱藏層可接受的輸出入大小，以免產生資料維度前後層對不上的問題。\n"
      ],
      "metadata": {
        "id": "i1bK6_Tux6Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCNN(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes=1000):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "      #============== 在此區塊新增或減少隱藏層 =================\n",
        "      nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      #============================================================\n",
        "    )\n",
        "    self.features2 = nn.Sequential(\n",
        "      #============== 可在此區塊新增隱藏層 =====================\n",
        "      \n",
        "      \n",
        "      \n",
        "      #===========================================================\n",
        "    )\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "    self.classifier = nn.Sequential(\n",
        "      #============== 在此區塊新增或減少隱藏層 =================\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(256 * 6 * 6, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(4096, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      # nn.Linear(4096, num_classes), # 原始模型輸出層\n",
        "      #===========================================================\n",
        "    )\n",
        "    self.classifier2 = nn.Sequential(\n",
        "      #============== 可在此區塊新增隱藏層 =====================\n",
        "      \n",
        "\n",
        "\n",
        "      #===========================================================\n",
        "      nn.Linear(4096, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.features2(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = self.classifier(x)\n",
        "    x = self.classifier2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "ORjQXKTVmyuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 訓練模型區塊\n",
        "包含視覺化模型及訓練模型。"
      ],
      "metadata": {
        "id": "lNezyEHCGbiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, device, dataloaders, class_names, num_images=6):\n",
        "  was_training = model.training\n",
        "  model.eval()\n",
        "  images_so_far = 0\n",
        "\n",
        "  plt.figure(figsize=(18,9))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "      for j in range(inputs.size()[0]):\n",
        "        images_so_far += 1\n",
        "\n",
        "        img_display = np.transpose(inputs.cpu().data[j].numpy(), (1,2,0)) #numpy:CHW, PIL:HWC\n",
        "        plt.subplot(num_images//2,2,images_so_far),plt.imshow(img_display) #nrow,ncol,image_idx\n",
        "        plt.title(f'predicted: {class_names[preds[j]]}')\n",
        "        plt.savefig(\"test.jpg\")\n",
        "        if images_so_far == num_images:\n",
        "            model.train(mode=was_training)\n",
        "            plt.clf()\n",
        "            return\n",
        "    plt.clf()\n",
        "    model.train(mode=was_training)\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "  \"\"\"Imshow for Tensor.\"\"\"\n",
        "  inp = inp.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  \n",
        "  #原先Normalize是對每個channel個別做 減去mean, 再除上std\n",
        "  inp1 = std * inp + mean\n",
        "\n",
        "  plt.imshow(inp)\n",
        "\n",
        "  if title is not None:\n",
        "      plt.title(title)\n",
        "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "  plt.imshow(inp1)\n",
        "  if title is not None:\n",
        "      plt.title(title)\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "dkP2g__jm8M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, device, dataloaders, dataset_sizes, optimizer, scheduler, num_epochs=25):\n",
        "  since = time.time()\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "  train_loss, valid_loss = [], []\n",
        "  train_acc, valid_acc = [], []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()  # Set model to training mode\n",
        "      else:\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      # Iterate over data.\n",
        "      for inputs, labels in tqdm(dataloaders[phase]):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            if phase == 'train':\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "\n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "      if phase == 'train':\n",
        "        train_loss.append(epoch_loss)\n",
        "        train_acc.append(epoch_acc)\n",
        "      else:\n",
        "        valid_loss.append(epoch_loss)\n",
        "        valid_acc.append(epoch_acc)\n",
        "\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        phase, epoch_loss, epoch_acc))\n",
        "\n",
        "      # deep copy the model\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "  plt.figure(0)\n",
        "  plt.plot(range(1,num_epochs+1,1), np.array(train_loss), 'r-', label= \"train loss\") #relative global step\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"./train_loss.png\")\n",
        "  plt.clf()\n",
        "\n",
        "  plt.figure(1)\n",
        "  plt.plot(range(1,num_epochs+1,1), np.array(valid_loss), 'b-', label= \"eval loss\") #--evaluate_during_training True 在啟用eval\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"./eval_loss.png\")\n",
        "  plt.clf()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "    time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  #torch.save(model.state_dict(),\"model.pt\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "g-dRfFb3q6Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 訓練參數 (可調整)\n",
        "* num_epochs: 訓練回合數\n",
        "* lr: 訓練速度(learning rate)\n",
        "* batch_size: 批次(batch)大小"
      ],
      "metadata": {
        "id": "ftlKnYzrqzeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "lr = 0.001\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "Jje5_QtQqu7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 主函式"
      ],
      "metadata": {
        "id": "4To2Db6HG8vI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbiXj6gt2nFY"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  num_workers = 2\n",
        "  momentum = 0.9\n",
        "\n",
        "  # 資料集載入 =======================================================================\n",
        "  data_dir = './dataset/training'\n",
        "  image_datasets = {\n",
        "    x: datasets.ImageFolder(\n",
        "      os.path.join(data_dir, x),\n",
        "      data_transforms[x]\n",
        "    ) \n",
        "    for x in ['train', 'val']\n",
        "  }\n",
        "  dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(\n",
        "      image_datasets[x], \n",
        "      batch_size=batch_size,\n",
        "      shuffle=True, \n",
        "      num_workers=num_workers\n",
        "    )\n",
        "    for x in ['train', 'val']\n",
        "  }\n",
        "  dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "  class_names = image_datasets['train'].classes\n",
        "  # 資料集載入 =======================================================================\n",
        "\n",
        "  # 設定 CUDA 環境 =======================================================================\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device {device}\\n\")\n",
        "  # 設定 CUDA 環境 =======================================================================\n",
        "\n",
        "\n",
        "  # Get a batch of training data\n",
        "  inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "  # Make a grid from batch\n",
        "  out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "  imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "  \n",
        "  # model =======================================================================\n",
        "  model_ft = MyCNN(num_classes=219)\n",
        "  pretrained_dict = load_state_dict_from_url(\n",
        "    'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    progress=True\n",
        "  )\n",
        "  model_dict = model_ft.state_dict()\n",
        "  # 1. filter out unnecessary keys\n",
        "  pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "  # 2. overwrite entries in the existing state dict\n",
        "  model_dict.update(pretrained_dict) \n",
        "  # 3. load the new state dict\n",
        "  model_ft.load_state_dict(model_dict)\n",
        "\n",
        "  for k,v in model_dict.items():\n",
        "    print(k)\n",
        "\n",
        "  model_ft = model_ft.to(device)\n",
        "  # model =======================================================================\n",
        "\n",
        "  parameter_count = count_parameters(model_ft)\n",
        "  print(f\"#parameters:{parameter_count}\")\n",
        "  print(f\"batch_size:{batch_size}\")\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Observe that all parameters are being optimized\n",
        "  optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "  # Decay LR by a factor of 0.1 every 7 epochs\n",
        "  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "  model_ft = train_model(\n",
        "    model_ft, \n",
        "    criterion, \n",
        "    device, \n",
        "    dataloaders, \n",
        "    dataset_sizes, \n",
        "    optimizer_ft, \n",
        "    exp_lr_scheduler,     \n",
        "    num_epochs=num_epochs\n",
        "  )\n",
        "\n",
        "  visualize_model(model_ft, device, dataloaders, class_names)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ML_HW2_sample_code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}